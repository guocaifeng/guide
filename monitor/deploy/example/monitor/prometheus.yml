global:
  scrape_interval: 15s # 每隔15秒，向exporter拉取已经采集到的的指标
  scrape_timeout: 10s  # 拉取指标超时时间 
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.

rule_files:
  - "node_down.yml"

scrape_configs:
#  - job_name: 'prometheus'
#    static_configs:
#    - targets: ['10.5.0.110:9090']
#
  - job_name: 'cadvisor'
    static_configs:
            - targets: ['10.5.1.16:9101','10.5.1.105:9101','10.5.1.35:9101','10.5.1.107:9101','10.5.1.202:9101','10.5.1.41:9101']
  
  - job_name: 'node-export'
    scrape_interval: 8s
    static_configs:
            - targets: ['10.5.1.16:9100','10.5.1.105:9100','10.5.1.35:9100','10.5.1.107:9100','10.5.1.202:9100','10.5.1.41:9100']
  
#  - job_name: 'postgres'
#    static_configs:
#    - targets: ['10.5.0.110:9187','192.168.58.129:9187']
#      labels:
#       instance: 'postgres'
#       platform: 'ec2'
##    - targets: ['192.168.58.129:9187']
##      labels:
##       instance: 'sht-sgmhadoopdn-03'
##       platform: 'ec2'

#  - job_name: 'rabbitmq'
#    static_configs:
#    - targets: ['10.5.0.110:9099','192.168.58.129:9099']  
  
    
#  ##配置监控的redis-exporter,如果目标有多个，那么直接按照列表方式填写
#  - job_name: 'redis_exporter_targets'
#    static_configs:
#      - targets:
#        - redis://first-redis-host:6379
#        - redis://second-redis-host:6379
#        - redis://second-redis-host:6380
#        - redis://second-redis-host:6381
#    metrics_path: /scrape  #指标路径
#    relabel_configs:
#      - source_labels: [__address__]
#        target_label: __param_target
#      - source_labels: [__param_target]
#        target_label: instance
#      - target_label: __address__
#        replacement: <<REDIS-EXPORTER-HOSTNAME>>:9121
#  
#  ##但实例监控
#  - job_name: 'redis_exporter_target'
#    static_configs:
#      - targets:
#        - <<REDIS-EXPORTER-HOSTNAME>>:9121
    
    
    
#告警
alerting:
  alertmanagers:
  - static_configs:
    - targets: ['10.5.1.16:9093']
